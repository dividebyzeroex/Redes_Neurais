{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe79f6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">ðŸŒ² Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "552ac2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Dataset\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f89832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_number</th>\n",
       "      <th>Ticket_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund Mr Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>21171</td>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>17599</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen Miss Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282</td>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>113803</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen Mr William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>373450</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                              Name     Sex   Age  SibSp  \\\n",
       "0                            Braund Mr Owen Harris    male  22.0      1   \n",
       "1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n",
       "2                             Heikkinen Miss Laina  female  26.0      0   \n",
       "3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n",
       "4                           Allen Mr William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n",
       "0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n",
       "1      0          PC 17599  71.2833   C85        C         17599          PC  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n",
       "3      0            113803  53.1000  C123        S        113803        NONE  \n",
       "4      0            373450   8.0500   NaN        S        373450        NONE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparando o dataset\n",
    "#tokenizando nomes, normalizando os dados\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Normalizing the text\n",
    "    def normalize_name(x):\n",
    "        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n",
    "    \n",
    "    def ticket_number(x):\n",
    "        return x.split(\" \")[-1]\n",
    "    \n",
    "    def ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return \"NONE\"\n",
    "        return \"_\".join(items[0:-1])\n",
    "    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n",
    "    return df\n",
    "\n",
    "preprocessed_train_df = preprocess(train_df)\n",
    "preprocessed_test_df = preprocess(test_df)\n",
    "\n",
    "preprocessed_train_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a255affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = list(preprocessed_train_df.columns)\n",
    "input_features.remove(\"Survived\")\n",
    "input_features.remove(\"PassengerId\")\n",
    "input_features.remove(\"Ticket\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b51db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting panda to ts\n",
    "\n",
    "def tokenize_names(features, labels=None):\n",
    "    features[\"Name\"] = tf.strings.to_hash_bucket_fast(features[\"Name\"], 1000)\n",
    "    return features, labels\n",
    "\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df, label=\"Survived\").map(tokenize_names)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_test_df).map(tokenize_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73385d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1744477551.794491 1260581 gradient_boosted_trees.cc:1873] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "W0000 00:00:1744477551.794503 1260581 gradient_boosted_trees.cc:1883] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "W0000 00:00:1744477551.794505 1260581 gradient_boosted_trees.cc:1897] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1744477551.882844 1260581 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1744477551.882853 1260581 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1744477551.882857 1260581 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: CATEGORICAL\n",
      "  categorial {\n",
      "    min_vocab_frequency: 0\n",
      "    max_vocab_count: -1\n",
      "  }\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Pclass$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Name$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Sex$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Age$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^SibSp$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Parch$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Fare$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Cabin$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Embarked$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Ticket_number$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^Ticket_item$\"\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: true\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1744477551.882966 1260581 kernel.cc:401] Number of batches: 1\n",
      "I0000 00:00:1744477551.882969 1260581 kernel.cc:402] Number of examples: 891\n",
      "I0000 00:00:1744477551.883096 1260581 data_spec_inference.cc:354] 147 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Cabin (0 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1744477551.883135 1260581 data_spec_inference.cc:354] 28 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_item (16 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1744477551.883197 1260581 data_spec_inference.cc:354] 671 item(s) have been pruned (i.e. they are considered out of dictionary) for the column Ticket_number (8 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
      "I0000 00:00:1744477551.883294 1260581 kernel.cc:802] Training dataset:\n",
      "Number of records: 891\n",
      "Number of columns: 12\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (50%)\n",
      "\tNUMERICAL: 6 (50%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (50%)\n",
      "\t1: \"Cabin\" CATEGORICAL num-nas:687 (77.1044%) has-dict vocab-size:1 num-oods:204 (100%)\n",
      "\t2: \"Embarked\" CATEGORICAL num-nas:2 (0.224467%) has-dict vocab-size:4 zero-ood-items most-frequent:\"S\" 644 (72.4409%)\n",
      "\t7: \"Sex\" CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 577 (64.7587%)\n",
      "\t9: \"Ticket_item\" CATEGORICAL has-dict vocab-size:17 num-oods:46 (5.16274%) most-frequent:\"NONE\" 665 (74.6352%)\n",
      "\t10: \"Ticket_number\" CATEGORICAL has-dict vocab-size:9 num-oods:842 (94.5006%) most-frequent:\"<OOD>\" 842 (94.5006%)\n",
      "\t11: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
      "\n",
      "NUMERICAL: 6 (50%)\n",
      "\t0: \"Age\" NUMERICAL num-nas:177 (19.8653%) mean:29.6991 min:0.42 max:80 sd:14.5163\n",
      "\t3: \"Fare\" NUMERICAL mean:32.2042 min:0 max:512.329 sd:49.6655\n",
      "\t4: \"Name\" NUMERICAL mean:492.103 min:4 max:999 sd:288.795\n",
      "\t5: \"Parch\" NUMERICAL mean:0.381594 min:0 max:6 sd:0.805605\n",
      "\t6: \"Pclass\" NUMERICAL mean:2.30864 min:1 max:3 sd:0.835602\n",
      "\t8: \"SibSp\" NUMERICAL mean:0.523008 min:0 max:8 sd:1.10212\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1744477551.883304 1260581 kernel.cc:818] Configure learner\n",
      "W0000 00:00:1744477551.883399 1260581 gradient_boosted_trees.cc:1873] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "W0000 00:00:1744477551.883401 1260581 gradient_boosted_trees.cc:1883] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "W0000 00:00:1744477551.883402 1260581 gradient_boosted_trees.cc:1897] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "I0000 00:00:1744477551.883450 1260581 kernel.cc:831] Training config:\n",
      "learner: \"GRADIENT_BOOSTED_TREES\"\n",
      "features: \"^Age$\"\n",
      "features: \"^Cabin$\"\n",
      "features: \"^Embarked$\"\n",
      "features: \"^Fare$\"\n",
      "features: \"^Name$\"\n",
      "features: \"^Parch$\"\n",
      "features: \"^Pclass$\"\n",
      "features: \"^Sex$\"\n",
      "features: \"^SibSp$\"\n",
      "features: \"^Ticket_item$\"\n",
      "features: \"^Ticket_number$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: CLASSIFICATION\n",
      "random_seed: 1234\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "pure_serving_model: false\n",
      "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
      "  num_trees: 2000\n",
      "  decision_tree {\n",
      "    max_depth: 6\n",
      "    min_examples: 1\n",
      "    in_split_min_examples_check: true\n",
      "    keep_non_leaf_label_distribution: true\n",
      "    num_candidate_attributes: -1\n",
      "    missing_value_policy: GLOBAL_IMPUTATION\n",
      "    allow_na_conditions: false\n",
      "    categorical_set_greedy_forward {\n",
      "      sampling: 0.1\n",
      "      max_num_items: -1\n",
      "      min_item_frequency: 1\n",
      "    }\n",
      "    growing_strategy_local {\n",
      "    }\n",
      "    categorical {\n",
      "      random {\n",
      "      }\n",
      "    }\n",
      "    sparse_oblique_split {\n",
      "      num_projections_exponent: 2\n",
      "      normalization: MIN_MAX\n",
      "    }\n",
      "    internal {\n",
      "      sorting_strategy: PRESORTED\n",
      "    }\n",
      "    uplift {\n",
      "      min_examples_in_treatment: 5\n",
      "      split_score: KULLBACK_LEIBLER\n",
      "    }\n",
      "    numerical_vector_sequence {\n",
      "      max_num_test_examples: 1000\n",
      "      num_random_selected_anchors: 100\n",
      "    }\n",
      "  }\n",
      "  shrinkage: 0.05\n",
      "  loss: DEFAULT\n",
      "  validation_set_ratio: 0.1\n",
      "  validation_interval_in_trees: 1\n",
      "  early_stopping: VALIDATION_LOSS_INCREASE\n",
      "  early_stopping_num_trees_look_ahead: 30\n",
      "  l2_regularization: 0\n",
      "  lambda_loss: 1\n",
      "  mart {\n",
      "  }\n",
      "  adapt_subsample_for_maximum_training_duration: false\n",
      "  l1_regularization: 0\n",
      "  use_hessian_gain: false\n",
      "  l2_regularization_categorical: 1\n",
      "  xe_ndcg {\n",
      "    ndcg_truncation: 5\n",
      "  }\n",
      "  stochastic_gradient_boosting {\n",
      "    ratio: 1\n",
      "  }\n",
      "  apply_link_function: true\n",
      "  compute_permutation_variable_importance: false\n",
      "  early_stopping_initial_iteration: 10\n",
      "}\n",
      "\n",
      "I0000 00:00:1744477551.883474 1260581 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/var/folders/bn/t0gq4m154_9gm5fx3ztc465c0000gn/T/tmp2bmug883/working_cache\"\n",
      "num_threads: 10\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1744477551.883507 1284910 kernel.cc:895] Train model\n",
      "I0000 00:00:1744477551.883553 1284910 gradient_boosted_trees.cc:577] Default loss set to BINOMIAL_LOG_LIKELIHOOD\n",
      "I0000 00:00:1744477551.883559 1284910 gradient_boosted_trees.cc:1190] Training gradient boosted tree on 891 example(s) and 11 feature(s).\n",
      "I0000 00:00:1744477551.883653 1284910 gradient_boosted_trees.cc:1230] 799 examples used for training and 92 examples used for validation\n",
      "I0000 00:00:1744477551.883669 1284910 gpu.cc:93] Cannot initialize GPU: Not compiled with GPU support\n",
      "I0000 00:00:1744477551.886768 1284910 gradient_boosted_trees.cc:1632] Train tree 1/2000 train-loss:1.265876 train-accuracy:0.624531 valid-loss:1.362916 valid-accuracy:0.543478 [total:0.00s iter:0.00s]\n",
      "I0000 00:00:1744477551.889811 1284910 gradient_boosted_trees.cc:1632] Train tree 2/2000 train-loss:1.213331 train-accuracy:0.624531 valid-loss:1.323821 valid-accuracy:0.543478 [total:0.01s iter:0.00s]\n",
      "I0000 00:00:1744477551.893074 1284910 gradient_boosted_trees.cc:1634] Train tree 3/2000 train-loss:1.165578 train-accuracy:0.624531 valid-loss:1.287851 valid-accuracy:0.543478 [total:0.01s iter:0.00s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75 Loss:1.0703905820846558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744477552.080247 1284910 early_stopping.cc:54] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.07039\n",
      "I0000 00:00:1744477552.080259 1284910 gradient_boosted_trees.cc:1669] Create final snapshot of the model at iteration 70\n",
      "I0000 00:00:1744477552.081689 1284910 gradient_boosted_trees.cc:279] Truncates the model to 41 tree(s) i.e. 41  iteration(s).\n",
      "I0000 00:00:1744477552.082079 1284910 gradient_boosted_trees.cc:341] Final model num-trees:41 valid-loss:1.070391 valid-accuracy:0.750000\n",
      "I0000 00:00:1744477552.082658 1284910 kernel.cc:926] Export model in log directory: /var/folders/bn/t0gq4m154_9gm5fx3ztc465c0000gn/T/tmp2bmug883 with prefix ca9aaa9f4aa24962\n",
      "I0000 00:00:1744477552.083503 1284910 kernel.cc:944] Save model in resources\n",
      "I0000 00:00:1744477552.084026 1260581 abstract_model.cc:921] Model self evaluation:\n",
      "Task: CLASSIFICATION\n",
      "Label: __LABEL\n",
      "Loss (BINOMIAL_LOG_LIKELIHOOD): 1.07039\n",
      "\n",
      "Accuracy: 0.75  CI95[W][0 1]\n",
      "ErrorRate: : 0.25\n",
      "\n",
      "\n",
      "Confusion Table:\n",
      "truth\\prediction\n",
      "    1   2\n",
      "1  43   7\n",
      "2  16  26\n",
      "Total: 92\n",
      "\n",
      "\n",
      "2025-04-12 14:05:52.087388: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1206] Loading model from path /var/folders/bn/t0gq4m154_9gm5fx3ztc465c0000gn/T/tmp2bmug883/model/ with prefix ca9aaa9f4aa24962\n",
      "I0000 00:00:1744477552.089348 1260581 decision_forest.cc:808] Model loaded with 41 root(s), 2237 node(s), and 10 input feature(s).\n",
      "I0000 00:00:1744477552.089362 1260581 abstract_model.cc:1439] Engine \"GradientBoostedTreesGeneric\" built\n",
      "2025-04-12 14:05:52.089366: I tensorflow_decision_forests/tensorflow/ops/inference/kernel.cc:1035] Use fast generic engine\n"
     ]
    }
   ],
   "source": [
    "#trainando o modelo\n",
    "model = tfdf.keras.GradientBoostedTreesModel(\n",
    "    verbose=0,\n",
    "    features=[tfdf.keras.FeatureUsage(name=n)\n",
    "              for n in input_features],\n",
    "              exclude_non_specified_features=True,\n",
    "              min_examples=1,\n",
    "              categorical_algorithm=\"RANDOM\",\n",
    "              shrinkage=0.05,\n",
    "              split_axis=\"SPARSE_OBLIQUE\",\n",
    "              sparse_oblique_normalization=\"MIN_MAX\",\n",
    "              sparse_oblique_num_projections_exponent=2.0,\n",
    "              num_trees=2000,\n",
    "              random_seed=1234)\n",
    "model.fit(train_ds)\n",
    "# Avaliando o modelo\n",
    "self_evaluation = model.make_inspector().evaluation()\n",
    "\n",
    "print(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23f40bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_boosted_trees_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 1 (1.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1 (1.00 Byte)\n",
      "_________________________________________________________________\n",
      "Type: \"GRADIENT_BOOSTED_TREES\"\n",
      "Task: CLASSIFICATION\n",
      "Label: \"__LABEL\"\n",
      "\n",
      "Input Features (11):\n",
      "\tAge\n",
      "\tCabin\n",
      "\tEmbarked\n",
      "\tFare\n",
      "\tName\n",
      "\tParch\n",
      "\tPclass\n",
      "\tSex\n",
      "\tSibSp\n",
      "\tTicket_item\n",
      "\tTicket_number\n",
      "\n",
      "No weights\n",
      "\n",
      "Variable Importance: INV_MEAN_MIN_DEPTH:\n",
      "    1.           \"Sex\"  1.000000 ################\n",
      "    2.        \"Pclass\"  0.410322 ####\n",
      "    3.           \"Age\"  0.350223 ###\n",
      "    4.          \"Fare\"  0.347501 ###\n",
      "    5.         \"SibSp\"  0.297281 ##\n",
      "    6.         \"Parch\"  0.276020 #\n",
      "    7.          \"Name\"  0.220359 \n",
      "    8.      \"Embarked\"  0.180701 \n",
      "    9. \"Ticket_number\"  0.176137 \n",
      "   10.   \"Ticket_item\"  0.175622 \n",
      "\n",
      "Variable Importance: NUM_AS_ROOT:\n",
      "    1. \"Sex\" 41.000000 \n",
      "\n",
      "Variable Importance: NUM_NODES:\n",
      "    1.          \"Fare\" 534.000000 ################\n",
      "    2.           \"Age\" 504.000000 ###############\n",
      "    3.        \"Pclass\" 413.000000 ############\n",
      "    4.         \"Parch\" 403.000000 ###########\n",
      "    5.          \"Name\" 372.000000 ##########\n",
      "    6.         \"SibSp\" 368.000000 ##########\n",
      "    7.           \"Sex\" 41.000000 \n",
      "    8.   \"Ticket_item\" 35.000000 \n",
      "    9.      \"Embarked\" 20.000000 \n",
      "   10. \"Ticket_number\" 18.000000 \n",
      "\n",
      "Variable Importance: SUM_SCORE:\n",
      "    1.           \"Sex\" 546.039467 ################\n",
      "    2.          \"Fare\" 469.269267 #############\n",
      "    3.        \"Pclass\" 427.506124 ############\n",
      "    4.           \"Age\" 399.053219 ###########\n",
      "    5.         \"SibSp\" 330.567771 #########\n",
      "    6.         \"Parch\" 281.300180 #######\n",
      "    7.          \"Name\" 182.796946 #####\n",
      "    8.   \"Ticket_item\" 19.061203 \n",
      "    9. \"Ticket_number\" 16.863035 \n",
      "   10.      \"Embarked\" 16.643790 \n",
      "\n",
      "\n",
      "\n",
      "Loss: BINOMIAL_LOG_LIKELIHOOD\n",
      "Validation loss value: 1.07039\n",
      "Number of trees per iteration: 1\n",
      "Node format: NOT_SET\n",
      "Number of trees: 41\n",
      "Total number of nodes: 2237\n",
      "\n",
      "Number of nodes by tree:\n",
      "Count: 41 Average: 54.561 StdDev: 5.76807\n",
      "Min: 37 Max: 63 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 37, 38) 1   2.44%   2.44% #\n",
      "[ 38, 39) 0   0.00%   2.44%\n",
      "[ 39, 41) 0   0.00%   2.44%\n",
      "[ 41, 42) 0   0.00%   2.44%\n",
      "[ 42, 43) 0   0.00%   2.44%\n",
      "[ 43, 45) 1   2.44%   4.88% #\n",
      "[ 45, 46) 2   4.88%   9.76% ###\n",
      "[ 46, 47) 0   0.00%   9.76%\n",
      "[ 47, 49) 2   4.88%  14.63% ###\n",
      "[ 49, 50) 1   2.44%  17.07% #\n",
      "[ 50, 51) 0   0.00%  17.07%\n",
      "[ 51, 53) 5  12.20%  29.27% #######\n",
      "[ 53, 54) 5  12.20%  41.46% #######\n",
      "[ 54, 55) 0   0.00%  41.46%\n",
      "[ 55, 57) 4   9.76%  51.22% ######\n",
      "[ 57, 58) 7  17.07%  68.29% ##########\n",
      "[ 58, 59) 0   0.00%  68.29%\n",
      "[ 59, 61) 7  17.07%  85.37% ##########\n",
      "[ 61, 62) 3   7.32%  92.68% ####\n",
      "[ 62, 63] 3   7.32% 100.00% ####\n",
      "\n",
      "Depth by leafs:\n",
      "Count: 1139 Average: 4.87621 StdDev: 0.403611\n",
      "Min: 2 Max: 5 Ignored: 0\n",
      "----------------------------------------------\n",
      "[ 2, 3)    1   0.09%   0.09%\n",
      "[ 3, 4)   28   2.46%   2.55%\n",
      "[ 4, 5)   82   7.20%   9.75% #\n",
      "[ 5, 5] 1028  90.25% 100.00% ##########\n",
      "\n",
      "Number of training obs by leaf:\n",
      "Count: 1139 Average: 28.7612 StdDev: 72.4905\n",
      "Min: 1 Max: 465 Ignored: 0\n",
      "----------------------------------------------\n",
      "[   1,  24) 903  79.28%  79.28% ##########\n",
      "[  24,  47)  85   7.46%  86.74% #\n",
      "[  47,  70)  45   3.95%  90.69%\n",
      "[  70,  94)  23   2.02%  92.71%\n",
      "[  94, 117)  11   0.97%  93.68%\n",
      "[ 117, 140)  10   0.88%  94.56%\n",
      "[ 140, 163)  10   0.88%  95.43%\n",
      "[ 163, 187)  10   0.88%  96.31%\n",
      "[ 187, 210)   2   0.18%  96.49%\n",
      "[ 210, 233)   2   0.18%  96.66%\n",
      "[ 233, 256)   0   0.00%  96.66%\n",
      "[ 256, 280)   1   0.09%  96.75%\n",
      "[ 280, 303)   1   0.09%  96.84%\n",
      "[ 303, 326)   6   0.53%  97.37%\n",
      "[ 326, 349)   0   0.00%  97.37%\n",
      "[ 349, 373)   4   0.35%  97.72%\n",
      "[ 373, 396)  11   0.97%  98.68%\n",
      "[ 396, 419)  10   0.88%  99.56%\n",
      "[ 419, 442)   2   0.18%  99.74%\n",
      "[ 442, 465]   3   0.26% 100.00%\n",
      "\n",
      "Attribute in nodes:\n",
      "\t504 : Age [NUMERICAL]\n",
      "\t319 : Fare [NUMERICAL]\n",
      "\t129 : Name [NUMERICAL]\n",
      "\t41 : Sex [CATEGORICAL]\n",
      "\t35 : Ticket_item [CATEGORICAL]\n",
      "\t20 : Embarked [CATEGORICAL]\n",
      "\t18 : Ticket_number [CATEGORICAL]\n",
      "\t17 : Parch [NUMERICAL]\n",
      "\t13 : Pclass [NUMERICAL]\n",
      "\t2 : SibSp [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 0:\n",
      "\t41 : Sex [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 1:\n",
      "\t48 : Age [NUMERICAL]\n",
      "\t41 : Sex [CATEGORICAL]\n",
      "\t26 : Fare [NUMERICAL]\n",
      "\t6 : Pclass [NUMERICAL]\n",
      "\t1 : Ticket_number [CATEGORICAL]\n",
      "\t1 : Embarked [CATEGORICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 2:\n",
      "\t129 : Age [NUMERICAL]\n",
      "\t68 : Fare [NUMERICAL]\n",
      "\t41 : Sex [CATEGORICAL]\n",
      "\t16 : Name [NUMERICAL]\n",
      "\t13 : Embarked [CATEGORICAL]\n",
      "\t8 : Pclass [NUMERICAL]\n",
      "\t5 : Ticket_number [CATEGORICAL]\n",
      "\t4 : Ticket_item [CATEGORICAL]\n",
      "\t2 : Parch [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 3:\n",
      "\t268 : Age [NUMERICAL]\n",
      "\t165 : Fare [NUMERICAL]\n",
      "\t51 : Name [NUMERICAL]\n",
      "\t41 : Sex [CATEGORICAL]\n",
      "\t16 : Ticket_item [CATEGORICAL]\n",
      "\t16 : Embarked [CATEGORICAL]\n",
      "\t12 : Ticket_number [CATEGORICAL]\n",
      "\t9 : Pclass [NUMERICAL]\n",
      "\t6 : Parch [NUMERICAL]\n",
      "\n",
      "Attribute in nodes with depth <= 5:\n",
      "\t504 : Age [NUMERICAL]\n",
      "\t319 : Fare [NUMERICAL]\n",
      "\t129 : Name [NUMERICAL]\n",
      "\t41 : Sex [CATEGORICAL]\n",
      "\t35 : Ticket_item [CATEGORICAL]\n",
      "\t20 : Embarked [CATEGORICAL]\n",
      "\t18 : Ticket_number [CATEGORICAL]\n",
      "\t17 : Parch [NUMERICAL]\n",
      "\t13 : Pclass [NUMERICAL]\n",
      "\t2 : SibSp [NUMERICAL]\n",
      "\n",
      "Condition type in nodes:\n",
      "\t984 : ObliqueCondition\n",
      "\t114 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 0:\n",
      "\t41 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 1:\n",
      "\t80 : ObliqueCondition\n",
      "\t43 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 2:\n",
      "\t223 : ObliqueCondition\n",
      "\t63 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 3:\n",
      "\t499 : ObliqueCondition\n",
      "\t85 : ContainsBitmapCondition\n",
      "Condition type in nodes with depth <= 5:\n",
      "\t984 : ObliqueCondition\n",
      "\t114 : ContainsBitmapCondition\n",
      "\n",
      "Training logs:\n",
      "Number of iteration to final model: 41\n",
      "\tIter:1 train-loss:1.265876 valid-loss:1.362916  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:2 train-loss:1.213331 valid-loss:1.323821  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:3 train-loss:1.165578 valid-loss:1.287851  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:4 train-loss:1.121409 valid-loss:1.263676  train-accuracy:0.624531 valid-accuracy:0.543478\n",
      "\tIter:5 train-loss:1.082690 valid-loss:1.237110  train-accuracy:0.795995 valid-accuracy:0.717391\n",
      "\tIter:6 train-loss:1.047732 valid-loss:1.214716  train-accuracy:0.823529 valid-accuracy:0.739130\n",
      "\tIter:16 train-loss:0.792858 valid-loss:1.106307  train-accuracy:0.901126 valid-accuracy:0.728261\n",
      "\tIter:26 train-loss:0.641859 valid-loss:1.080849  train-accuracy:0.922403 valid-accuracy:0.750000\n",
      "\tIter:36 train-loss:0.545784 valid-loss:1.087721  train-accuracy:0.937422 valid-accuracy:0.739130\n",
      "\tIter:46 train-loss:0.477734 valid-loss:1.079020  train-accuracy:0.944931 valid-accuracy:0.750000\n",
      "\tIter:56 train-loss:0.420992 valid-loss:1.096483  train-accuracy:0.951189 valid-accuracy:0.739130\n",
      "\tIter:66 train-loss:0.374675 valid-loss:1.119793  train-accuracy:0.954944 valid-accuracy:0.739130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b375b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function InferenceCoreModel.make_predict_function.<locals>.predict_function_trained at 0x1575a4f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Submission file saved to ./kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "\n",
    "def prediction_to_kaggle_format(model, threshold=0):\n",
    "    proba_survive = model.predict(test_ds, verbose=0)[:,0]\n",
    "    return pd.DataFrame({\n",
    "        \"PassengerId\": preprocessed_test_df[\"PassengerId\"],\n",
    "        \"Survived\": (proba_survive > threshold).astype(int)\n",
    "    })\n",
    "\n",
    "def make_submission(kaggle_predictions):\n",
    "    path=\"./kaggle/working/submission.csv\"\n",
    "    kaggle_predictions.to_csv(path, index=False)\n",
    "    print(f\"Submission file saved to {path}\")\n",
    "\n",
    "kaggle_predictions = prediction_to_kaggle_format(model)\n",
    "make_submission(kaggle_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
